{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a6f7d41",
   "metadata": {},
   "source": [
    "# Let's stop being gullible. You can't predict stocks with a simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2dbb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5137c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get these from Alpacas\n",
    "api_key = ...\n",
    "api_secret_key = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca6410",
   "metadata": {},
   "source": [
    "#### The function below is to be used for shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_prices(symbols, interval = '1Day', start_date = None):\n",
    "    \n",
    "    \n",
    "    def fetch(url, next_page_token = None):\n",
    "        \n",
    "        if next_page_token:\n",
    "            url+=f'&page_token={next_page_token}'\n",
    "            \n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"APCA-API-KEY-ID\": api_key,\n",
    "            \"APCA-API-SECRET-KEY\": api_secret_key\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, verify=False)\n",
    "\n",
    "        data = json.loads(response.text)\n",
    "        try:\n",
    "            next_page_token = 'stop' if str(data['next_page_token']) == 'None' else str(data['next_page_token'])\n",
    "        except:\n",
    "            next_page_token = 'stop'\n",
    "        \n",
    "        return data['bars'], next_page_token\n",
    "    \n",
    "    if start_date:\n",
    "        url = f\"https://data.alpaca.markets/v2/stocks/bars?symbols={'%2C'.join(symbols)}&timeframe={interval}&start={start_date}&limit=10000&adjustment=raw&feed=iex\"\n",
    "    else:\n",
    "        url = f\"https://data.alpaca.markets/v2/stocks/bars?symbols={'%2C'.join(symbols)}&timeframe={interval}&limit=10000&adjustment=raw&feed=iex\"\n",
    "\n",
    "    historical_prices = {}\n",
    "    \n",
    "    next_page_token = None\n",
    "    while next_page_token != 'stop':\n",
    "        data, next_page_token = fetch(url, next_page_token)\n",
    "        print(next_page_token)\n",
    "        historical_prices.update(data)\n",
    "    \n",
    "    print(historical_prices)\n",
    "    print('Data Downloaded')\n",
    "    \n",
    "    prices = [[[dict['t'],dict['c']] for dict in historical_prices[symbol]] for symbol in symbols]\n",
    "    \n",
    "    active_symbols = []\n",
    "    stocks = {}\n",
    "    for i in range(len(symbols)):\n",
    "        try:\n",
    "            stocks[symbols[i]] = pd.DataFrame(prices[i], columns=['date', 'close']).sort_values(by='date', ascending=True)\n",
    "            active_symbols.append(symbols[i])\n",
    "        except:\n",
    "            print('bug with: ', symbols[i])\n",
    "            \n",
    "    return stocks, list(stocks.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b22881",
   "metadata": {},
   "source": [
    "#### This one is for BTC/USD (No need API KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_prices(symbols, interval = '1Day', start_date = None):\n",
    "    \n",
    "    def fetch(url, next_page_token = None):\n",
    "        \n",
    "        if next_page_token:\n",
    "            url+=f'&page_token={next_page_token}'\n",
    "\n",
    "        response = requests.get(url, verify=False)\n",
    "\n",
    "        data = json.loads(response.text)\n",
    "        try:\n",
    "            next_page_token = 'stop' if str(data['next_page_token']) == 'None' else str(data['next_page_token'])\n",
    "        except:\n",
    "            next_page_token = 'stop'\n",
    "        \n",
    "        return data['bars'], next_page_token\n",
    "    \n",
    "    if start_date:\n",
    "        url = f\"https://data.alpaca.markets/v1beta3/crypto/us/bars?symbols={'%2C'.join(symbols)}&timeframe={interval}&start={start_date}&limit=10000\"\n",
    "    else:\n",
    "        url = f\"https://data.alpaca.markets/v1beta3/crypto/us/bars?symbols={'%2C'.join(symbols)}&timeframe={interval}&limit=10000\"\n",
    "\n",
    "    historical_prices = {}\n",
    "    \n",
    "    next_page_token = None\n",
    "    while next_page_token != 'stop':\n",
    "        data, next_page_token = fetch(url, next_page_token)\n",
    "        print(next_page_token)\n",
    "        historical_prices.update(data)\n",
    "    \n",
    "    print(historical_prices)\n",
    "    print('Data Downloaded')\n",
    "    \n",
    "    prices = [[[dict['t'],dict['c']] for dict in historical_prices[symbol]] for symbol in symbols]\n",
    "    \n",
    "    active_symbols = []\n",
    "    stocks = {}\n",
    "    for i in range(len(symbols)):\n",
    "        try:\n",
    "            stocks[symbols[i]] = pd.DataFrame(prices[i], columns=['date', 'close']).sort_values(by='date', ascending=True)\n",
    "            active_symbols.append(symbols[i])\n",
    "        except:\n",
    "            print('bug with: ', symbols[i])\n",
    "            \n",
    "    return stocks, list(stocks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea78795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data, i.e MSFT here\n",
    "symbols = ['MSFT']\n",
    "stocks, symbols = get_historical_prices(symbols, interval='1Day', start_date='2020-09-01')\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90871912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataFrame\n",
    "df = stocks['MSFT'][['date', 'close']]\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22bbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_values = scaler.fit_transform(np.array(df.sort_values(by='date', ascending=True)['close']).reshape(-1,1))\n",
    "\n",
    "scaled_df = df.copy()\n",
    "scaled_df['close'] = scaled_values\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test data without shuffle\n",
    "train_df, test_df = train_test_split(scaled_df, test_size=0.2, shuffle=False)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the train rolling window for the LSTM\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(30, len(train_df)):\n",
    "    x_train.append(train_df.iloc[i-30:i]['close'])\n",
    "    y_train.append(train_df.iloc[i]['close'])\n",
    "    \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae03120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the test rolling window for the LSTM\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(30, len(test_df)):\n",
    "    x_test.append(test_df.iloc[i-30:i]['close'])\n",
    "    y_test.append(test_df.iloc[i]['close'])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2966c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(layers.LSTM(64, return_sequences=False))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c401bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model and fit to train data\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(x_train, y_train, batch_size= 1, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380de69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "predictions = model.predict(x_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "validation = test_df[30:].copy()\n",
    "validation['predictions'] = predictions\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price USD ($)')\n",
    "plt.plot(df['close'])\n",
    "plt.plot(validation[['predictions']])\n",
    "plt.legend(['Base', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22f4c3",
   "metadata": {},
   "source": [
    "## Back to reality\n",
    "\n",
    "#### The first algorithm is more accurate but much slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f81453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Create a time series\n",
    "df_train = df.iloc[:-100].copy()\n",
    "time_series = np.array(df_train['close'])\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "normalized_series = scaler.fit_transform(time_series.reshape(-1, 1))\n",
    "\n",
    "# Training data\n",
    "lookback = 30\n",
    "X_train, y_train = [], []\n",
    "for i in range(len(normalized_series) - lookback):\n",
    "    X_train.append(normalized_series[i:i+lookback, 0])\n",
    "    y_train.append(normalized_series[i+lookback, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Test data\n",
    "last_instances = normalized_series[-lookback:]\n",
    "X_test = np.array([last_instances])\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Prediction\n",
    "predicted_values = []\n",
    "\n",
    "for i in trange(100):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(lookback, 1)))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=1, verbose=0)\n",
    "    predicted_value = model.predict(X_test)\n",
    "    X_test = np.reshape(np.array([np.concatenate((X_test.reshape(lookback,)[1:], predicted_value[0])).reshape(-1, 1)]), (X_test.shape[0], X_test.shape[1], 1))\n",
    "    predicted_values.append(scaler.inverse_transform(predicted_value)[0][0])\n",
    "\n",
    "print(\"Predicted values:\", predicted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd447dad",
   "metadata": {},
   "source": [
    "#### Less accurate but much faster !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b59797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "df_train = df.iloc[:-100].copy()\n",
    "\n",
    "# Création d'une série temporelle fictive\n",
    "time_series = np.array(df_train['close'])\n",
    "\n",
    "# Normalisation de la série temporelle\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "normalized_series = scaler.fit_transform(time_series.reshape(-1, 1))\n",
    "\n",
    "# Préparation des données d'entraînement\n",
    "lookback = 30  # Nombre d'instants de temps antérieurs à utiliser pour la prédiction\n",
    "X_train, y_train = [], []\n",
    "for i in range(len(normalized_series) - lookback):\n",
    "    X_train.append(normalized_series[i:i+lookback, 0])\n",
    "    y_train.append(normalized_series[i+lookback, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "# Remodelage des données pour l'entrée dans le LSTM (batch_size, timesteps, features)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Construction du modèle LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(lookback, 1)))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=1, verbose=1)\n",
    "\n",
    "# Préparation des données de test (derniers instants de temps de la série)\n",
    "last_instances = normalized_series[-lookback:]\n",
    "X_test = np.array([last_instances])\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Prédiction des prochaines valeurs\n",
    "predicted_values = []\n",
    "\n",
    "for i in range(100):\n",
    "    predicted_value = model.predict(X_test)\n",
    "    print(predicted_value)\n",
    "    X_test = np.reshape(np.array([np.concatenate((X_test.reshape(lookback,)[1:], predicted_value[0])).reshape(-1, 1)]), (X_test.shape[0], X_test.shape[1], 1))\n",
    "    predicted_values.append(scaler.inverse_transform(predicted_value)[0][0])\n",
    "\n",
    "print(\"Valeurs prédites:\", predicted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f609454",
   "metadata": {},
   "source": [
    "#### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4128a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.DataFrame(index=[k for k in range(len(df_train['close']), len(df_train['close'])+len(predicted_values))])\n",
    "validation['predictions'] = predicted_values\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price USD ($)')\n",
    "plt.plot(df['close'])\n",
    "plt.plot(validation[['predictions']])\n",
    "plt.legend(['Base', 'Predictions'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
